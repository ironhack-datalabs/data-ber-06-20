{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges\n",
    "\n",
    "1. Complete the custom `quotes_parser()` function so that the result being returned contains the quote string instead of the whole html page content.\n",
    "\n",
    "2. In `IronhackSpider.scrape_url()`, catch any error that might occur when you make requests to scrape the webpage. This includes checking the response status code and catching http request problems such as timeout, SSL, and too many redirects.\n",
    "\n",
    "3. In `IronhackSpider.kickstart()`, implement `sleep_interval`. You will check if `self.sleep_interval` is larger than 0. If so, tell the script to sleep the given amount of time before making the next request.\n",
    "\n",
    "4. Change the `PAGES_TO_SCRAPE` value to 10. Try if your code still works as intended by scraping the quotes in 10 webpages. If there are errors in your code, fix them.\n",
    "\n",
    "5. Update the parameters passed to the `IronhackSpider` constructor so that you coder can crawl [books.toscrape.com](http://books.toscrape.com/). You will need to use a different `URL_PATTERN` and write another parser function to be passed to `IronhackSpider`. \n",
    "\n",
    "6. [Bonus 1] Use techniques such as randomized user agents and referers in your requests to reduce the likelihood that your spider is blocked by websites. [Here](http://blog.adnansiddiqi.me/5-strategies-to-write-unblock-able-web-scrapers-in-python/) is a great article to learn these techniques.\n",
    "\n",
    "7. [Bonus 2] Implement asynchronous calls to `IronhackSpider`. You will make requests in parallel to complete your tasks faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "class IronhackSpider:\n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.rate = rate\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    def scrape_url(self, url):\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            content = self.get_response_content(response)\n",
    "            if not self.content_parser is None:\n",
    "                result = self.content_parser(content)\n",
    "            else:\n",
    "                result = content\n",
    "        except:\n",
    "            result = None\n",
    "        self.output_results(result)\n",
    "    \n",
    "    def get_response_content(self, r):\n",
    "        if (r.status_code == 200):\n",
    "            return r.content\n",
    "        return False\n",
    "        \n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "        \n",
    "    def kickstart(self):\n",
    "        for i in range(1, self.pages_to_scrape+1):\n",
    "            self.scrape_url(self.url_pattern % i)\n",
    "            if self.sleep_interval > 0:\n",
    "                time.sleep(self.sleep_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL_PATTERN = 'http://quotes.toscrape.com/page/%s/'\n",
    "\n",
    "PAGES_TO_SCRAPE = 3\n",
    "\n",
    "def quotes_parser(content):\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    quotes = soup.find_all('span', {'class':'text'})\n",
    "    results = [quote.text for quote in quotes]\n",
    "    return results\n",
    "\n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE, content_parser=quotes_parser)\n",
    "\n",
    "my_spider.kickstart()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
